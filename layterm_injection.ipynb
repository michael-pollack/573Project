{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "554e6858-1ef3-4cf3-b402-ed26572b95cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from -r requirements.txt (line 1)) (3.9.1)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from -r requirements.txt (line 2)) (1.9.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from -r requirements.txt (line 3)) (1.6.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from -r requirements.txt (line 4)) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from -r requirements.txt (line 5)) (3.10.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from -r requirements.txt (line 6)) (2.2.4)\n",
      "Requirement already satisfied: seaborn in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from -r requirements.txt (line 7)) (0.13.2)\n",
      "Requirement already satisfied: tabulate in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from -r requirements.txt (line 8)) (0.9.0)\n",
      "Requirement already satisfied: fastparquet in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from -r requirements.txt (line 9)) (2024.11.0)\n",
      "Requirement already satisfied: click in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk->-r requirements.txt (line 1)) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk->-r requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk->-r requirements.txt (line 1)) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk->-r requirements.txt (line 1)) (4.66.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wordcloud->-r requirements.txt (line 2)) (11.2.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn->-r requirements.txt (line 3)) (1.15.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn->-r requirements.txt (line 3)) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas->-r requirements.txt (line 4)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas->-r requirements.txt (line 4)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas->-r requirements.txt (line 4)) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->-r requirements.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->-r requirements.txt (line 5)) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->-r requirements.txt (line 5)) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->-r requirements.txt (line 5)) (3.2.3)\n",
      "Requirement already satisfied: cramjam>=2.3 in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from fastparquet->-r requirements.txt (line 9)) (2.10.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from fastparquet->-r requirements.txt (line 9)) (2025.3.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 4)) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\avery\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from click->nltk->-r requirements.txt (line 1)) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\avery\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt\n",
    "#pip installs a list of libraries\n",
    "#list can be found in requirements.txt\n",
    "\n",
    "#important import names\n",
    "#import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#import numpy as np\n",
    "#import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e56a42af-56df-4c2f-819b-1c59ae3b2de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\avery\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\avery\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\avery\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\avery\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\avery\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\avery\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\avery\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\avery\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.classify import ClassifierI\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('tagsets')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "509aef29-39f3-474c-b7d7-0412b017a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elife_train = pd.read_parquet('data/Elife/train-00000-of-00001.parquet')\n",
    "#get df for development data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c38f796f-0074-4d35-bcb1-780d28f20eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "      <th>section_headings</th>\n",
       "      <th>keywords</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In temperate climates , winter deaths exceed s...</td>\n",
       "      <td>In the USA , more deaths happen in the winter ...</td>\n",
       "      <td>[Abstract, Introduction, Results, Discussion, ...</td>\n",
       "      <td>[epidemiology, and, global, health]</td>\n",
       "      <td>2018</td>\n",
       "      <td>National and regional seasonal dynamics of all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whether complement dysregulation directly cont...</td>\n",
       "      <td>Most people have likely experienced the discom...</td>\n",
       "      <td>[Abstract, Introduction, Results, Discussion, ...</td>\n",
       "      <td>[microbiology, and, infectious, disease, immun...</td>\n",
       "      <td>2019</td>\n",
       "      <td>Complement and CD4+ T cells drive context-spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Variation in the presentation of hereditary im...</td>\n",
       "      <td>The immune system protects an individual from ...</td>\n",
       "      <td>[Abstract, Introduction, Results, Discussion, ...</td>\n",
       "      <td>[microbiology, and, infectious, disease, immun...</td>\n",
       "      <td>2015</td>\n",
       "      <td>Phenotypic complementation of genetic immunode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rapid and flexible interpretation of conflicti...</td>\n",
       "      <td>The brain adapts to control our behavior in di...</td>\n",
       "      <td>[Abstract, Introduction, Results, Discussion, ...</td>\n",
       "      <td>[neuroscience]</td>\n",
       "      <td>2016</td>\n",
       "      <td>Cascade of neural processing orchestrates cogn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Myosin 5a is a dual-headed molecular motor tha...</td>\n",
       "      <td>Cells use motor proteins that to move organell...</td>\n",
       "      <td>[Abstract, Introduction, Results, Discussion, ...</td>\n",
       "      <td>[structural, biology, and, molecular, biophysics]</td>\n",
       "      <td>2015</td>\n",
       "      <td>Structural dynamics of myosin 5 during process...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0  In temperate climates , winter deaths exceed s...   \n",
       "1  Whether complement dysregulation directly cont...   \n",
       "2  Variation in the presentation of hereditary im...   \n",
       "3  Rapid and flexible interpretation of conflicti...   \n",
       "4  Myosin 5a is a dual-headed molecular motor tha...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  In the USA , more deaths happen in the winter ...   \n",
       "1  Most people have likely experienced the discom...   \n",
       "2  The immune system protects an individual from ...   \n",
       "3  The brain adapts to control our behavior in di...   \n",
       "4  Cells use motor proteins that to move organell...   \n",
       "\n",
       "                                    section_headings  \\\n",
       "0  [Abstract, Introduction, Results, Discussion, ...   \n",
       "1  [Abstract, Introduction, Results, Discussion, ...   \n",
       "2  [Abstract, Introduction, Results, Discussion, ...   \n",
       "3  [Abstract, Introduction, Results, Discussion, ...   \n",
       "4  [Abstract, Introduction, Results, Discussion, ...   \n",
       "\n",
       "                                            keywords  year  \\\n",
       "0                [epidemiology, and, global, health]  2018   \n",
       "1  [microbiology, and, infectious, disease, immun...  2019   \n",
       "2  [microbiology, and, infectious, disease, immun...  2015   \n",
       "3                                     [neuroscience]  2016   \n",
       "4  [structural, biology, and, molecular, biophysics]  2015   \n",
       "\n",
       "                                               title  \n",
       "0  National and regional seasonal dynamics of all...  \n",
       "1  Complement and CD4+ T cells drive context-spec...  \n",
       "2  Phenotypic complementation of genetic immunode...  \n",
       "3  Cascade of neural processing orchestrates cogn...  \n",
       "4  Structural dynamics of myosin 5 during process...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_elife_train.head(5)\n",
    "#check data exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db14ba63-634b-48f8-a083-8af8a1e9b424",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_summ_list = df_elife_train.summary.tolist()\n",
    "#grab all summaries and put them in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e99d61e1-d040-4072-8c50-0c26002b3e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_summ = og_summ_list[28]\n",
    "#genomes, DNA\n",
    "#target words for summary #28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d87c3ee-1d6f-474a-9554-45a1f9abbd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_dict = {\"genome\" : [(\"complete set of genetic instructions\", \"NN\"), (\"complete sets of genetic instructions\", \"NNS\")]}\n",
    "#sample dictionairy in the form of key:lemma value:list of tuples where each tuples is a pair of layterm and POS tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b723326b-1116-4379-8602-920c412b7019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Our genome'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_summ[:10]\n",
    "#test data present -> genome/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda7abaf-fed5-4509-b31c-46655eaf2d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_injections(doc):\n",
    "    \"\"\"A function to inject layterms. Takes in a summary and Creates parallel documents, one in raw form and \n",
    "    one containing the lemmatized version of each token\"\"\"\n",
    "    lemma_doc = []\n",
    "    raw_doc =[]\n",
    "    doc_sents = nltk.sent_tokenize(doc)\n",
    "    regex_token = RegexpTokenizer(r\"([a-zA-Z]+(?:â€™[a-z]+)?)\")\n",
    "    for sent in doc_sents:\n",
    "        #print(type(sent))\n",
    "        doc = regex_token.tokenize(sent)\n",
    "        doc = [word.lower() for word in doc]\n",
    "        doc = pos_tag(doc)\n",
    "        lemmatizer = WordNetLemmatizer() \n",
    "        doc2 = [(lemmatizer.lemmatize(word[0]), word[1]) for word in doc]\n",
    "        lemma_doc.append(doc2)\n",
    "        raw_doc.append(doc)\n",
    "    #print(len(raw_doc))\n",
    "    #print(len(lemma_doc))\n",
    "    #print(raw_doc)\n",
    "    #print(lemma_doc)\n",
    "    #doc = [(word[0], get_wordnet_pos(word[1])) for word in doc]\n",
    "    #lemmatizer = WordNetLemmatizer() \n",
    "    #doc = [lemmatizer.lemmatize(word[0], word[1]) for word in doc]\n",
    "    return raw_doc, lemma_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce9a1b0f-1fa5-43af-8ec3-39fa55069de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "22\n",
      "[[('our', 'PRP$'), ('genomes', 'NNS'), ('contain', 'VBP'), ('around', 'IN'), ('different', 'JJ'), ('genes', 'NNS'), ('that', 'WDT'), ('code', 'VBP'), ('for', 'IN'), ('instructions', 'NNS'), ('to', 'TO'), ('create', 'VB'), ('proteins', 'NNS'), ('and', 'CC'), ('other', 'JJ'), ('important', 'JJ'), ('molecules', 'NNS')], [('when', 'WRB'), ('changes', 'NNS'), ('or', 'CC'), ('mutations', 'NNS'), ('occur', 'VBP'), ('within', 'IN'), ('these', 'DT'), ('genes', 'NNS'), ('malfunctioning', 'VBG'), ('proteins', 'NNS'), ('that', 'WDT'), ('are', 'VBP'), ('damaging', 'VBG'), ('to', 'TO'), ('the', 'DT'), ('cell', 'NN'), ('may', 'MD'), ('be', 'VB'), ('produced', 'VBN')], [('researchers', 'NNS'), ('of', 'IN'), ('human', 'JJ'), ('genetics', 'NNS'), ('have', 'VBP'), ('tried', 'VBN'), ('to', 'TO'), ('spot', 'VB'), ('the', 'DT'), ('genetic', 'JJ'), ('mutations', 'NNS'), ('that', 'WDT'), ('are', 'VBP'), ('associated', 'VBN'), ('with', 'IN'), ('illnesses', 'NNS'), ('for', 'IN'), ('example', 'NN'), ('heart', 'NN'), ('diseases', 'NNS')], [('however', 'RB'), ('they', 'PRP'), ('found', 'VBP'), ('that', 'IN'), ('most', 'JJS'), ('of', 'IN'), ('these', 'DT'), ('mutations', 'NNS'), ('are', 'VBP'), ('actually', 'RB'), ('located', 'VBN'), ('outside', 'IN'), ('of', 'IN'), ('genes', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('non', 'NN'), ('coding', 'VBG'), ('areas', 'NNS'), ('that', 'WDT'), ('make', 'VBP'), ('up', 'RP'), ('the', 'DT'), ('majority', 'NN'), ('of', 'IN'), ('our', 'PRP$'), ('genome', 'NN')], [('these', 'DT'), ('mutations', 'NNS'), ('do', 'VBP'), ('not', 'RB'), ('modify', 'VB'), ('proteins', 'NNS'), ('directly', 'RB'), ('which', 'WDT'), ('makes', 'VBZ'), ('it', 'PRP'), ('challenging', 'VBG'), ('to', 'TO'), ('understand', 'VB'), ('how', 'WRB'), ('they', 'PRP'), ('may', 'MD'), ('be', 'VB'), ('related', 'VBN'), ('to', 'TO'), ('heart', 'NN'), ('conditions', 'NNS')], [('one', 'CD'), ('possibility', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('the', 'DT'), ('genetic', 'JJ'), ('changes', 'NNS'), ('affect', 'VBP'), ('regions', 'NNS'), ('called', 'VBD'), ('enhancers', 'NNS'), ('which', 'WDT'), ('control', 'VBP'), ('where', 'WRB'), ('when', 'WRB'), ('and', 'CC'), ('how', 'WRB'), ('much', 'RB'), ('a', 'DT'), ('gene', 'NN'), ('is', 'VBZ'), ('turned', 'VBN'), ('on', 'IN'), ('by', 'IN'), ('physically', 'RB'), ('interacting', 'VBG'), ('with', 'IN'), ('it', 'PRP')], [('mutations', 'NNS'), ('in', 'IN'), ('enhancers', 'NNS'), ('could', 'MD'), ('lead', 'VB'), ('to', 'TO'), ('a', 'DT'), ('gene', 'NN'), ('producing', 'VBG'), ('too', 'RB'), ('much', 'JJ'), ('or', 'CC'), ('too', 'RB'), ('little', 'JJ'), ('of', 'IN'), ('a', 'DT'), ('protein', 'NN'), ('which', 'WDT'), ('might', 'MD'), ('create', 'VB'), ('problems', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('cell', 'NN')], [('yet', 'RB'), ('it', 'PRP'), ('is', 'VBZ'), ('difficult', 'JJ'), ('to', 'TO'), ('match', 'VB'), ('an', 'DT'), ('enhancer', 'NN'), ('with', 'IN'), ('the', 'DT'), ('gene', 'NN'), ('or', 'CC'), ('genes', 'NNS'), ('it', 'PRP'), ('controls', 'VBZ')], [('one', 'CD'), ('reason', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('a', 'DT'), ('non', 'JJ'), ('coding', 'VBG'), ('region', 'NN'), ('can', 'MD'), ('influence', 'VB'), ('a', 'DT'), ('gene', 'NN'), ('placed', 'VBD'), ('far', 'RB'), ('away', 'RB'), ('on', 'IN'), ('the', 'DT'), ('dna', 'NN'), ('strand', 'NN')], [('indeed', 'RB'), ('the', 'DT'), ('long', 'JJ'), ('dna', 'NN'), ('molecule', 'NN'), ('precisely', 'RB'), ('folds', 'VBZ'), ('in', 'IN'), ('on', 'IN'), ('itself', 'PRP'), ('to', 'TO'), ('fit', 'VB'), ('inside', 'IN'), ('its', 'PRP$'), ('compartment', 'NN'), ('in', 'IN'), ('the', 'DT'), ('cell', 'NN'), ('which', 'WDT'), ('can', 'MD'), ('bring', 'VB'), ('together', 'RB'), ('distant', 'JJ'), ('sequences', 'NNS')], [('montefiori', 'NNS'), ('et', 'VBP'), ('al', 'NN')], [('take', 'VB'), ('over', 'RP'), ('non', 'JJ'), ('coding', 'VBG'), ('areas', 'NNS'), ('which', 'WDT'), ('can', 'MD'), ('carry', 'VB'), ('mutations', 'NNS'), ('associated', 'VBN'), ('with', 'IN'), ('heart', 'NN'), ('diseases', 'NNS'), ('and', 'CC'), ('use', 'VB'), ('a', 'DT'), ('technique', 'NN'), ('called', 'VBN'), ('hi', 'NN'), ('c', 'NN'), ('to', 'TO'), ('try', 'VB'), ('to', 'TO'), ('identify', 'VB'), ('which', 'WDT'), ('genes', 'NNS'), ('these', 'DT'), ('regions', 'NNS'), ('may', 'MD'), ('control', 'VB')], [('the', 'DT'), ('tool', 'NN'), ('can', 'MD'), ('model', 'VB'), ('the', 'DT'), ('d', 'JJ'), ('organization', 'NN'), ('of', 'IN'), ('the', 'DT'), ('genome', 'NN'), ('and', 'CC'), ('it', 'PRP'), ('was', 'VBD'), ('further', 'RBR'), ('modified', 'VBN'), ('to', 'TO'), ('capture', 'VB'), ('only', 'RB'), ('the', 'DT'), ('regions', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('genome', 'NN'), ('that', 'WDT'), ('contain', 'VBP'), ('genes', 'NNS'), ('and', 'CC'), ('the', 'DT'), ('dna', 'NN'), ('sequences', 'VBZ'), ('that', 'IN'), ('interact', 'NN'), ('with', 'IN'), ('them', 'PRP'), ('in', 'IN'), ('human', 'JJ'), ('heart', 'NN'), ('cells', 'NNS')], [('this', 'DT'), ('helped', 'VBD'), ('to', 'TO'), ('create', 'VB'), ('a', 'DT'), ('d', 'JJ'), ('map', 'NN'), ('of', 'IN'), ('genes', 'NNS'), ('which', 'WDT'), ('come', 'VBP'), ('in', 'IN'), ('contact', 'NN'), ('with', 'IN'), ('the', 'DT'), ('non', 'NN'), ('coding', 'VBG'), ('areas', 'NNS'), ('that', 'WDT'), ('carry', 'VBP'), ('mutations', 'NNS'), ('associated', 'VBN'), ('with', 'IN'), ('heart', 'NN'), ('diseases', 'NNS')], [('in', 'IN'), ('fact', 'NN'), ('deleting', 'VBG'), ('those', 'DT'), ('genes', 'NNS'), ('often', 'RB'), ('causes', 'VBZ'), ('heart', 'NN'), ('disorders', 'NNS'), ('in', 'IN'), ('mice', 'NN')], [('in', 'IN'), ('addition', 'NN'), ('montefiori', 'FW'), ('et', 'FW'), ('al', 'NN')], [('reveal', 'NN'), ('that', 'IN'), ('of', 'IN'), ('the', 'DT'), ('non', 'NN'), ('coding', 'VBG'), ('regions', 'NNS'), ('examined', 'VBN'), ('were', 'VBD'), ('influencing', 'VBG'), ('genes', 'NNS'), ('that', 'WDT'), ('were', 'VBD'), ('far', 'RB'), ('away', 'RB')], [('this', 'DT'), ('shows', 'VBZ'), ('that', 'IN'), ('despite', 'IN'), ('a', 'DT'), ('common', 'JJ'), ('assumption', 'NN'), ('enhancers', 'NNS'), ('often', 'RB'), ('do', 'VBP'), ('not', 'RB'), ('regulate', 'VB'), ('the', 'DT'), ('coding', 'NN'), ('sequences', 'NNS'), ('they', 'PRP'), ('are', 'VBP'), ('nearest', 'JJS'), ('to', 'TO'), ('on', 'IN'), ('the', 'DT'), ('dna', 'NN'), ('strand', 'NN')], [('pinpointing', 'VBG'), ('the', 'DT'), ('genes', 'NNS'), ('regulated', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('non', 'NN'), ('coding', 'VBG'), ('regions', 'NNS'), ('involved', 'VBN'), ('in', 'IN'), ('cardiovascular', 'JJ'), ('diseases', 'NNS'), ('could', 'MD'), ('lead', 'VB'), ('to', 'TO'), ('new', 'JJ'), ('ways', 'NNS'), ('of', 'IN'), ('treating', 'VBG'), ('or', 'CC'), ('preventing', 'VBG'), ('these', 'DT'), ('conditions', 'NNS')], [('the', 'DT'), ('d', 'NN'), ('map', 'NN'), ('created', 'VBN'), ('by', 'IN'), ('montefiori', 'JJ'), ('et', 'NNS'), ('al', 'VBP')], [('may', 'MD'), ('also', 'RB'), ('help', 'VB'), ('to', 'TO'), ('visualize', 'VB'), ('how', 'WRB'), ('the', 'DT'), ('genetic', 'JJ'), ('information', 'NN'), ('is', 'VBZ'), ('organized', 'VBN'), ('in', 'IN'), ('heart', 'NN'), ('cells', 'NNS')], [('this', 'DT'), ('will', 'MD'), ('contribute', 'VB'), ('to', 'TO'), ('the', 'DT'), ('current', 'JJ'), ('effort', 'NN'), ('to', 'TO'), ('understand', 'VB'), ('the', 'DT'), ('role', 'NN'), ('of', 'IN'), ('the', 'DT'), ('d', 'NN'), ('structure', 'NN'), ('of', 'IN'), ('the', 'DT'), ('genome', 'NN'), ('especially', 'RB'), ('in', 'IN'), ('different', 'JJ'), ('cell', 'NN'), ('types', 'NNS')]]\n",
      "[[('our', 'PRP$'), ('genome', 'NNS'), ('contain', 'VBP'), ('around', 'IN'), ('different', 'JJ'), ('gene', 'NNS'), ('that', 'WDT'), ('code', 'VBP'), ('for', 'IN'), ('instruction', 'NNS'), ('to', 'TO'), ('create', 'VB'), ('protein', 'NNS'), ('and', 'CC'), ('other', 'JJ'), ('important', 'JJ'), ('molecule', 'NNS')], [('when', 'WRB'), ('change', 'NNS'), ('or', 'CC'), ('mutation', 'NNS'), ('occur', 'VBP'), ('within', 'IN'), ('these', 'DT'), ('gene', 'NNS'), ('malfunctioning', 'VBG'), ('protein', 'NNS'), ('that', 'WDT'), ('are', 'VBP'), ('damaging', 'VBG'), ('to', 'TO'), ('the', 'DT'), ('cell', 'NN'), ('may', 'MD'), ('be', 'VB'), ('produced', 'VBN')], [('researcher', 'NNS'), ('of', 'IN'), ('human', 'JJ'), ('genetics', 'NNS'), ('have', 'VBP'), ('tried', 'VBN'), ('to', 'TO'), ('spot', 'VB'), ('the', 'DT'), ('genetic', 'JJ'), ('mutation', 'NNS'), ('that', 'WDT'), ('are', 'VBP'), ('associated', 'VBN'), ('with', 'IN'), ('illness', 'NNS'), ('for', 'IN'), ('example', 'NN'), ('heart', 'NN'), ('disease', 'NNS')], [('however', 'RB'), ('they', 'PRP'), ('found', 'VBP'), ('that', 'IN'), ('most', 'JJS'), ('of', 'IN'), ('these', 'DT'), ('mutation', 'NNS'), ('are', 'VBP'), ('actually', 'RB'), ('located', 'VBN'), ('outside', 'IN'), ('of', 'IN'), ('gene', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('non', 'NN'), ('coding', 'VBG'), ('area', 'NNS'), ('that', 'WDT'), ('make', 'VBP'), ('up', 'RP'), ('the', 'DT'), ('majority', 'NN'), ('of', 'IN'), ('our', 'PRP$'), ('genome', 'NN')], [('these', 'DT'), ('mutation', 'NNS'), ('do', 'VBP'), ('not', 'RB'), ('modify', 'VB'), ('protein', 'NNS'), ('directly', 'RB'), ('which', 'WDT'), ('make', 'VBZ'), ('it', 'PRP'), ('challenging', 'VBG'), ('to', 'TO'), ('understand', 'VB'), ('how', 'WRB'), ('they', 'PRP'), ('may', 'MD'), ('be', 'VB'), ('related', 'VBN'), ('to', 'TO'), ('heart', 'NN'), ('condition', 'NNS')], [('one', 'CD'), ('possibility', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('the', 'DT'), ('genetic', 'JJ'), ('change', 'NNS'), ('affect', 'VBP'), ('region', 'NNS'), ('called', 'VBD'), ('enhancer', 'NNS'), ('which', 'WDT'), ('control', 'VBP'), ('where', 'WRB'), ('when', 'WRB'), ('and', 'CC'), ('how', 'WRB'), ('much', 'RB'), ('a', 'DT'), ('gene', 'NN'), ('is', 'VBZ'), ('turned', 'VBN'), ('on', 'IN'), ('by', 'IN'), ('physically', 'RB'), ('interacting', 'VBG'), ('with', 'IN'), ('it', 'PRP')], [('mutation', 'NNS'), ('in', 'IN'), ('enhancer', 'NNS'), ('could', 'MD'), ('lead', 'VB'), ('to', 'TO'), ('a', 'DT'), ('gene', 'NN'), ('producing', 'VBG'), ('too', 'RB'), ('much', 'JJ'), ('or', 'CC'), ('too', 'RB'), ('little', 'JJ'), ('of', 'IN'), ('a', 'DT'), ('protein', 'NN'), ('which', 'WDT'), ('might', 'MD'), ('create', 'VB'), ('problem', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('cell', 'NN')], [('yet', 'RB'), ('it', 'PRP'), ('is', 'VBZ'), ('difficult', 'JJ'), ('to', 'TO'), ('match', 'VB'), ('an', 'DT'), ('enhancer', 'NN'), ('with', 'IN'), ('the', 'DT'), ('gene', 'NN'), ('or', 'CC'), ('gene', 'NNS'), ('it', 'PRP'), ('control', 'VBZ')], [('one', 'CD'), ('reason', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('a', 'DT'), ('non', 'JJ'), ('coding', 'VBG'), ('region', 'NN'), ('can', 'MD'), ('influence', 'VB'), ('a', 'DT'), ('gene', 'NN'), ('placed', 'VBD'), ('far', 'RB'), ('away', 'RB'), ('on', 'IN'), ('the', 'DT'), ('dna', 'NN'), ('strand', 'NN')], [('indeed', 'RB'), ('the', 'DT'), ('long', 'JJ'), ('dna', 'NN'), ('molecule', 'NN'), ('precisely', 'RB'), ('fold', 'VBZ'), ('in', 'IN'), ('on', 'IN'), ('itself', 'PRP'), ('to', 'TO'), ('fit', 'VB'), ('inside', 'IN'), ('it', 'PRP$'), ('compartment', 'NN'), ('in', 'IN'), ('the', 'DT'), ('cell', 'NN'), ('which', 'WDT'), ('can', 'MD'), ('bring', 'VB'), ('together', 'RB'), ('distant', 'JJ'), ('sequence', 'NNS')], [('montefiori', 'NNS'), ('et', 'VBP'), ('al', 'NN')], [('take', 'VB'), ('over', 'RP'), ('non', 'JJ'), ('coding', 'VBG'), ('area', 'NNS'), ('which', 'WDT'), ('can', 'MD'), ('carry', 'VB'), ('mutation', 'NNS'), ('associated', 'VBN'), ('with', 'IN'), ('heart', 'NN'), ('disease', 'NNS'), ('and', 'CC'), ('use', 'VB'), ('a', 'DT'), ('technique', 'NN'), ('called', 'VBN'), ('hi', 'NN'), ('c', 'NN'), ('to', 'TO'), ('try', 'VB'), ('to', 'TO'), ('identify', 'VB'), ('which', 'WDT'), ('gene', 'NNS'), ('these', 'DT'), ('region', 'NNS'), ('may', 'MD'), ('control', 'VB')], [('the', 'DT'), ('tool', 'NN'), ('can', 'MD'), ('model', 'VB'), ('the', 'DT'), ('d', 'JJ'), ('organization', 'NN'), ('of', 'IN'), ('the', 'DT'), ('genome', 'NN'), ('and', 'CC'), ('it', 'PRP'), ('wa', 'VBD'), ('further', 'RBR'), ('modified', 'VBN'), ('to', 'TO'), ('capture', 'VB'), ('only', 'RB'), ('the', 'DT'), ('region', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('genome', 'NN'), ('that', 'WDT'), ('contain', 'VBP'), ('gene', 'NNS'), ('and', 'CC'), ('the', 'DT'), ('dna', 'NN'), ('sequence', 'VBZ'), ('that', 'IN'), ('interact', 'NN'), ('with', 'IN'), ('them', 'PRP'), ('in', 'IN'), ('human', 'JJ'), ('heart', 'NN'), ('cell', 'NNS')], [('this', 'DT'), ('helped', 'VBD'), ('to', 'TO'), ('create', 'VB'), ('a', 'DT'), ('d', 'JJ'), ('map', 'NN'), ('of', 'IN'), ('gene', 'NNS'), ('which', 'WDT'), ('come', 'VBP'), ('in', 'IN'), ('contact', 'NN'), ('with', 'IN'), ('the', 'DT'), ('non', 'NN'), ('coding', 'VBG'), ('area', 'NNS'), ('that', 'WDT'), ('carry', 'VBP'), ('mutation', 'NNS'), ('associated', 'VBN'), ('with', 'IN'), ('heart', 'NN'), ('disease', 'NNS')], [('in', 'IN'), ('fact', 'NN'), ('deleting', 'VBG'), ('those', 'DT'), ('gene', 'NNS'), ('often', 'RB'), ('cause', 'VBZ'), ('heart', 'NN'), ('disorder', 'NNS'), ('in', 'IN'), ('mouse', 'NN')], [('in', 'IN'), ('addition', 'NN'), ('montefiori', 'FW'), ('et', 'FW'), ('al', 'NN')], [('reveal', 'NN'), ('that', 'IN'), ('of', 'IN'), ('the', 'DT'), ('non', 'NN'), ('coding', 'VBG'), ('region', 'NNS'), ('examined', 'VBN'), ('were', 'VBD'), ('influencing', 'VBG'), ('gene', 'NNS'), ('that', 'WDT'), ('were', 'VBD'), ('far', 'RB'), ('away', 'RB')], [('this', 'DT'), ('show', 'VBZ'), ('that', 'IN'), ('despite', 'IN'), ('a', 'DT'), ('common', 'JJ'), ('assumption', 'NN'), ('enhancer', 'NNS'), ('often', 'RB'), ('do', 'VBP'), ('not', 'RB'), ('regulate', 'VB'), ('the', 'DT'), ('coding', 'NN'), ('sequence', 'NNS'), ('they', 'PRP'), ('are', 'VBP'), ('nearest', 'JJS'), ('to', 'TO'), ('on', 'IN'), ('the', 'DT'), ('dna', 'NN'), ('strand', 'NN')], [('pinpointing', 'VBG'), ('the', 'DT'), ('gene', 'NNS'), ('regulated', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('non', 'NN'), ('coding', 'VBG'), ('region', 'NNS'), ('involved', 'VBN'), ('in', 'IN'), ('cardiovascular', 'JJ'), ('disease', 'NNS'), ('could', 'MD'), ('lead', 'VB'), ('to', 'TO'), ('new', 'JJ'), ('way', 'NNS'), ('of', 'IN'), ('treating', 'VBG'), ('or', 'CC'), ('preventing', 'VBG'), ('these', 'DT'), ('condition', 'NNS')], [('the', 'DT'), ('d', 'NN'), ('map', 'NN'), ('created', 'VBN'), ('by', 'IN'), ('montefiori', 'JJ'), ('et', 'NNS'), ('al', 'VBP')], [('may', 'MD'), ('also', 'RB'), ('help', 'VB'), ('to', 'TO'), ('visualize', 'VB'), ('how', 'WRB'), ('the', 'DT'), ('genetic', 'JJ'), ('information', 'NN'), ('is', 'VBZ'), ('organized', 'VBN'), ('in', 'IN'), ('heart', 'NN'), ('cell', 'NNS')], [('this', 'DT'), ('will', 'MD'), ('contribute', 'VB'), ('to', 'TO'), ('the', 'DT'), ('current', 'JJ'), ('effort', 'NN'), ('to', 'TO'), ('understand', 'VB'), ('the', 'DT'), ('role', 'NN'), ('of', 'IN'), ('the', 'DT'), ('d', 'NN'), ('structure', 'NN'), ('of', 'IN'), ('the', 'DT'), ('genome', 'NN'), ('especially', 'RB'), ('in', 'IN'), ('different', 'JJ'), ('cell', 'NN'), ('type', 'NNS')]]\n"
     ]
    }
   ],
   "source": [
    "raw, lemma = create_injections(test_summ)\n",
    "#check that raw data and lemmatized data are of same lenght, sentence tokenizaiton is stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10b5697c-2ee3-43e8-9b31-729c4a875129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence index:  0 word index:  1 ('complete sets of genetic instructions', 'NNS')\n",
      "sentence index:  3 word index:  26 ('complete set of genetic instructions', 'NN')\n",
      "sentence index:  12 word index:  9 ('complete set of genetic instructions', 'NN')\n",
      "sentence index:  12 word index:  22 ('complete set of genetic instructions', 'NN')\n",
      "sentence index:  21 word index:  17 ('complete set of genetic instructions', 'NN')\n"
     ]
    }
   ],
   "source": [
    "#This was built to prototype the find function. I'm leaving it here for clarity now but will delete later\n",
    "for i in range(0, len(lemma)): #for every sentence\n",
    "    for j in range(0, len(lemma[i])): # for every word in every sentence\n",
    "        #print(lemma[i][j])\n",
    "        if lemma[i][j][0] in term_dict: #if word in term_dict\n",
    "            #print(lemma[i][j][0])\n",
    "            dict_list = term_dict[lemma[i][j][0]] #get the list of values\n",
    "            for k in dict_list: #loop through list\n",
    "                if lemma[i][j][1] == k[1]: #if term found print its location in both docs\n",
    "                    print(\"sentence index: \", i, \"word index: \", j, k)\n",
    "                    #word at S0W1 = genomes\n",
    "                    #word at S3W26 = genome\n",
    "                    #word at S12W9 = genome\n",
    "                    #S12W22 = genome\n",
    "                    #S21W17 = genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "046050c6-5826-4057-9208-b26d9af88fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(lemma):\n",
    "    \"\"\"function for matching the location in the raw doc with contents of the lemma doc at the parallel location\"\"\"\n",
    "    collect = []\n",
    "    for sent_id in range(0, len(lemma)): #for every sentence\n",
    "        for word_id in range(0, len(lemma[sent_id])): # for every word in every sentence\n",
    "            #print(lemma[i][j])\n",
    "            if lemma[sent_id][word_id][0] in term_dict: #if word in term_dict\n",
    "                #print(lemma[i][j][0])\n",
    "                dict_list = term_dict[lemma[sent_id][word_id][0]] #get the list of values\n",
    "                for layterm_tag in dict_list: #loop through list\n",
    "                    #print(k[1])\n",
    "                    #print(\"GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG\")\n",
    "                    if lemma[sent_id][word_id][1] == layterm_tag[1]:\n",
    "                        collect.append((sent_id, word_id, layterm_tag[0], layterm_tag[1]))\n",
    "    return collect\n",
    "                        #print(\"sentence index: \", i, \"word index: \", j, k[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "115a6382-a79b-4843-b61b-acc82907cc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1, 'complete sets of genetic instructions', 'NNS'), (3, 26, 'complete set of genetic instructions', 'NN'), (12, 9, 'complete set of genetic instructions', 'NN'), (12, 22, 'complete set of genetic instructions', 'NN'), (21, 17, 'complete set of genetic instructions', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "rep_list = find(lemma)\n",
    "print(rep_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54ba951f-9092-4cea-b40e-42a23ecaf319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(rep_list, raw):\n",
    "    \"\"\"function to replace med term with layterm\"\"\"\n",
    "    for loc in rep_list:\n",
    "        sent_ind = loc[0]\n",
    "        word_ind = loc[1]\n",
    "        layt = loc[2]\n",
    "        layt_tag = loc[3]\n",
    "        raw[sent_ind][word_ind] = (layt, layt_tag)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a287531-77f3-4e11-8888-ec46b825bfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = replace(rep_list, raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a597a3f3-31b3-4e39-837d-072529ad96fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('our', 'PRP$'), ('complete sets of genetic instructions', 'NNS'), ('contain', 'VBP'), ('around', 'IN'), ('different', 'JJ'), ('genes', 'NNS'), ('that', 'WDT'), ('code', 'VBP'), ('for', 'IN'), ('instructions', 'NNS'), ('to', 'TO'), ('create', 'VB'), ('proteins', 'NNS'), ('and', 'CC'), ('other', 'JJ'), ('important', 'JJ'), ('molecules', 'NNS')], [('when', 'WRB'), ('changes', 'NNS'), ('or', 'CC'), ('mutations', 'NNS'), ('occur', 'VBP'), ('within', 'IN'), ('these', 'DT'), ('genes', 'NNS'), ('malfunctioning', 'VBG'), ('proteins', 'NNS'), ('that', 'WDT'), ('are', 'VBP'), ('damaging', 'VBG'), ('to', 'TO'), ('the', 'DT'), ('cell', 'NN'), ('may', 'MD'), ('be', 'VB'), ('produced', 'VBN')], [('researchers', 'NNS'), ('of', 'IN'), ('human', 'JJ'), ('genetics', 'NNS'), ('have', 'VBP'), ('tried', 'VBN'), ('to', 'TO'), ('spot', 'VB'), ('the', 'DT'), ('genetic', 'JJ'), ('mutations', 'NNS'), ('that', 'WDT'), ('are', 'VBP'), ('associated', 'VBN'), ('with', 'IN'), ('illnesses', 'NNS'), ('for', 'IN'), ('example', 'NN'), ('heart', 'NN'), ('diseases', 'NNS')], [('however', 'RB'), ('they', 'PRP'), ('found', 'VBP'), ('that', 'IN'), ('most', 'JJS'), ('of', 'IN'), ('these', 'DT'), ('mutations', 'NNS'), ('are', 'VBP'), ('actually', 'RB'), ('located', 'VBN'), ('outside', 'IN'), ('of', 'IN'), ('genes', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('non', 'NN'), ('coding', 'VBG'), ('areas', 'NNS'), ('that', 'WDT'), ('make', 'VBP'), ('up', 'RP'), ('the', 'DT'), ('majority', 'NN'), ('of', 'IN'), ('our', 'PRP$'), ('complete set of genetic instructions', 'NN')], [('these', 'DT'), ('mutations', 'NNS'), ('do', 'VBP'), ('not', 'RB'), ('modify', 'VB'), ('proteins', 'NNS'), ('directly', 'RB'), ('which', 'WDT'), ('makes', 'VBZ'), ('it', 'PRP'), ('challenging', 'VBG'), ('to', 'TO'), ('understand', 'VB'), ('how', 'WRB'), ('they', 'PRP'), ('may', 'MD'), ('be', 'VB'), ('related', 'VBN'), ('to', 'TO'), ('heart', 'NN'), ('conditions', 'NNS')], [('one', 'CD'), ('possibility', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('the', 'DT'), ('genetic', 'JJ'), ('changes', 'NNS'), ('affect', 'VBP'), ('regions', 'NNS'), ('called', 'VBD'), ('enhancers', 'NNS'), ('which', 'WDT'), ('control', 'VBP'), ('where', 'WRB'), ('when', 'WRB'), ('and', 'CC'), ('how', 'WRB'), ('much', 'RB'), ('a', 'DT'), ('gene', 'NN'), ('is', 'VBZ'), ('turned', 'VBN'), ('on', 'IN'), ('by', 'IN'), ('physically', 'RB'), ('interacting', 'VBG'), ('with', 'IN'), ('it', 'PRP')], [('mutations', 'NNS'), ('in', 'IN'), ('enhancers', 'NNS'), ('could', 'MD'), ('lead', 'VB'), ('to', 'TO'), ('a', 'DT'), ('gene', 'NN'), ('producing', 'VBG'), ('too', 'RB'), ('much', 'JJ'), ('or', 'CC'), ('too', 'RB'), ('little', 'JJ'), ('of', 'IN'), ('a', 'DT'), ('protein', 'NN'), ('which', 'WDT'), ('might', 'MD'), ('create', 'VB'), ('problems', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('cell', 'NN')], [('yet', 'RB'), ('it', 'PRP'), ('is', 'VBZ'), ('difficult', 'JJ'), ('to', 'TO'), ('match', 'VB'), ('an', 'DT'), ('enhancer', 'NN'), ('with', 'IN'), ('the', 'DT'), ('gene', 'NN'), ('or', 'CC'), ('genes', 'NNS'), ('it', 'PRP'), ('controls', 'VBZ')], [('one', 'CD'), ('reason', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('a', 'DT'), ('non', 'JJ'), ('coding', 'VBG'), ('region', 'NN'), ('can', 'MD'), ('influence', 'VB'), ('a', 'DT'), ('gene', 'NN'), ('placed', 'VBD'), ('far', 'RB'), ('away', 'RB'), ('on', 'IN'), ('the', 'DT'), ('dna', 'NN'), ('strand', 'NN')], [('indeed', 'RB'), ('the', 'DT'), ('long', 'JJ'), ('dna', 'NN'), ('molecule', 'NN'), ('precisely', 'RB'), ('folds', 'VBZ'), ('in', 'IN'), ('on', 'IN'), ('itself', 'PRP'), ('to', 'TO'), ('fit', 'VB'), ('inside', 'IN'), ('its', 'PRP$'), ('compartment', 'NN'), ('in', 'IN'), ('the', 'DT'), ('cell', 'NN'), ('which', 'WDT'), ('can', 'MD'), ('bring', 'VB'), ('together', 'RB'), ('distant', 'JJ'), ('sequences', 'NNS')], [('montefiori', 'NNS'), ('et', 'VBP'), ('al', 'NN')], [('take', 'VB'), ('over', 'RP'), ('non', 'JJ'), ('coding', 'VBG'), ('areas', 'NNS'), ('which', 'WDT'), ('can', 'MD'), ('carry', 'VB'), ('mutations', 'NNS'), ('associated', 'VBN'), ('with', 'IN'), ('heart', 'NN'), ('diseases', 'NNS'), ('and', 'CC'), ('use', 'VB'), ('a', 'DT'), ('technique', 'NN'), ('called', 'VBN'), ('hi', 'NN'), ('c', 'NN'), ('to', 'TO'), ('try', 'VB'), ('to', 'TO'), ('identify', 'VB'), ('which', 'WDT'), ('genes', 'NNS'), ('these', 'DT'), ('regions', 'NNS'), ('may', 'MD'), ('control', 'VB')], [('the', 'DT'), ('tool', 'NN'), ('can', 'MD'), ('model', 'VB'), ('the', 'DT'), ('d', 'JJ'), ('organization', 'NN'), ('of', 'IN'), ('the', 'DT'), ('complete set of genetic instructions', 'NN'), ('and', 'CC'), ('it', 'PRP'), ('was', 'VBD'), ('further', 'RBR'), ('modified', 'VBN'), ('to', 'TO'), ('capture', 'VB'), ('only', 'RB'), ('the', 'DT'), ('regions', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('complete set of genetic instructions', 'NN'), ('that', 'WDT'), ('contain', 'VBP'), ('genes', 'NNS'), ('and', 'CC'), ('the', 'DT'), ('dna', 'NN'), ('sequences', 'VBZ'), ('that', 'IN'), ('interact', 'NN'), ('with', 'IN'), ('them', 'PRP'), ('in', 'IN'), ('human', 'JJ'), ('heart', 'NN'), ('cells', 'NNS')], [('this', 'DT'), ('helped', 'VBD'), ('to', 'TO'), ('create', 'VB'), ('a', 'DT'), ('d', 'JJ'), ('map', 'NN'), ('of', 'IN'), ('genes', 'NNS'), ('which', 'WDT'), ('come', 'VBP'), ('in', 'IN'), ('contact', 'NN'), ('with', 'IN'), ('the', 'DT'), ('non', 'NN'), ('coding', 'VBG'), ('areas', 'NNS'), ('that', 'WDT'), ('carry', 'VBP'), ('mutations', 'NNS'), ('associated', 'VBN'), ('with', 'IN'), ('heart', 'NN'), ('diseases', 'NNS')], [('in', 'IN'), ('fact', 'NN'), ('deleting', 'VBG'), ('those', 'DT'), ('genes', 'NNS'), ('often', 'RB'), ('causes', 'VBZ'), ('heart', 'NN'), ('disorders', 'NNS'), ('in', 'IN'), ('mice', 'NN')], [('in', 'IN'), ('addition', 'NN'), ('montefiori', 'FW'), ('et', 'FW'), ('al', 'NN')], [('reveal', 'NN'), ('that', 'IN'), ('of', 'IN'), ('the', 'DT'), ('non', 'NN'), ('coding', 'VBG'), ('regions', 'NNS'), ('examined', 'VBN'), ('were', 'VBD'), ('influencing', 'VBG'), ('genes', 'NNS'), ('that', 'WDT'), ('were', 'VBD'), ('far', 'RB'), ('away', 'RB')], [('this', 'DT'), ('shows', 'VBZ'), ('that', 'IN'), ('despite', 'IN'), ('a', 'DT'), ('common', 'JJ'), ('assumption', 'NN'), ('enhancers', 'NNS'), ('often', 'RB'), ('do', 'VBP'), ('not', 'RB'), ('regulate', 'VB'), ('the', 'DT'), ('coding', 'NN'), ('sequences', 'NNS'), ('they', 'PRP'), ('are', 'VBP'), ('nearest', 'JJS'), ('to', 'TO'), ('on', 'IN'), ('the', 'DT'), ('dna', 'NN'), ('strand', 'NN')], [('pinpointing', 'VBG'), ('the', 'DT'), ('genes', 'NNS'), ('regulated', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('non', 'NN'), ('coding', 'VBG'), ('regions', 'NNS'), ('involved', 'VBN'), ('in', 'IN'), ('cardiovascular', 'JJ'), ('diseases', 'NNS'), ('could', 'MD'), ('lead', 'VB'), ('to', 'TO'), ('new', 'JJ'), ('ways', 'NNS'), ('of', 'IN'), ('treating', 'VBG'), ('or', 'CC'), ('preventing', 'VBG'), ('these', 'DT'), ('conditions', 'NNS')], [('the', 'DT'), ('d', 'NN'), ('map', 'NN'), ('created', 'VBN'), ('by', 'IN'), ('montefiori', 'JJ'), ('et', 'NNS'), ('al', 'VBP')], [('may', 'MD'), ('also', 'RB'), ('help', 'VB'), ('to', 'TO'), ('visualize', 'VB'), ('how', 'WRB'), ('the', 'DT'), ('genetic', 'JJ'), ('information', 'NN'), ('is', 'VBZ'), ('organized', 'VBN'), ('in', 'IN'), ('heart', 'NN'), ('cells', 'NNS')], [('this', 'DT'), ('will', 'MD'), ('contribute', 'VB'), ('to', 'TO'), ('the', 'DT'), ('current', 'JJ'), ('effort', 'NN'), ('to', 'TO'), ('understand', 'VB'), ('the', 'DT'), ('role', 'NN'), ('of', 'IN'), ('the', 'DT'), ('d', 'NN'), ('structure', 'NN'), ('of', 'IN'), ('the', 'DT'), ('complete set of genetic instructions', 'NN'), ('especially', 'RB'), ('in', 'IN'), ('different', 'JJ'), ('cell', 'NN'), ('types', 'NNS')]]\n"
     ]
    }
   ],
   "source": [
    "print(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f6d38a-0fdf-474f-91a3-db072b30f7f9",
   "metadata": {},
   "source": [
    "So the goal of this code is to do a big find and replace. We create two parallel documents, one thats the \"raw\" document that contains teh article split by sentence then word, where each word is tagged with its POS. The 'lemma\" doc is split the same but instead of using words we use lemmas. This allows us to do a two part check to make sure we're inputing the right word in the right location, by matching on both the lemma and POS. This allows for more accurate tagging and avoids issues with homographs. Currently this code is designed to run on one single article. It needs to be optimized to run on some kind of data structure full of articles and maybe wrapped into a single function. the out put of that function needs to be a real readable summary, currently it spits out the separated tokenized pos tagged version. This needs to be stripped and joined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5b1a386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we DON'T split by sentence?\n",
    "\n",
    "def make_lemma_doc(og_doc):\n",
    "    doc = og_doc.split()\n",
    "    doc = [word.lower() for word in doc]\n",
    "    pos_doc = pos_tag(doc)\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    lemmas = [(lemmatizer.lemmatize(word[0]), word[1]) for word in pos_doc]\n",
    "    return doc, lemmas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e6303c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHat if we did find+replace at the same time instead of having two methods?\n",
    "def find_and_replace(raw, lemma):\n",
    "    \"\"\"function for matching the location in the raw doc with contents of the lemma doc at the parallel location\"\"\"\n",
    "    for word_id in range(0, len(lemma)): # For every word in the document\n",
    "        curr_lemma_pos = lemma[word_id] # Get the current lemma,POS pair\n",
    "        curr_lemma = curr_lemma_pos[0] # Get the current word's lemma\n",
    "        if curr_lemma in term_dict: # If the lemma is in the dictionary\n",
    "            replace_options = term_dict[curr_lemma] # Get the list of replacement options\n",
    "            for layterm_tag in replace_options: # For every layterm, POS pair in the options\n",
    "                if curr_lemma_pos[1] == layterm_tag[1]: # If the current POS matches the layterm POS\n",
    "                    raw[word_id] = layterm_tag[0] # Replace the word in the raw doc with the new replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "585618a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summ = test_summ\n",
    "raw2, lemma = make_lemma_doc(summ) # Make raw and lemma versions of the summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f5e071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['our', 'complete sets of genetic instructions', 'contain', 'around', '20', ',', '000', 'different', 'genes', 'that', 'code', 'for', 'instructions', 'to', 'create', 'proteins', 'and', 'other', 'important', 'molecules', '.', 'when', 'changes', ',', 'or', 'mutations', ',', 'occur', 'within', 'these', 'genes', ',', 'malfunctioning', 'proteins', 'that', 'are', 'damaging', 'to', 'the', 'cell', 'may', 'be', 'produced', '.', 'researchers', 'of', 'human', 'genetics', 'have', 'tried', 'to', 'spot', 'the', 'genetic', 'mutations', 'that', 'are', 'associated', 'with', 'illnesses', ',', 'for', 'example', 'heart', 'diseases', '.', 'however', ',', 'they', 'found', 'that', 'most', 'of', 'these', 'mutations', 'are', 'actually', 'located', 'outside', 'of', 'genes', ',', 'in', 'the', 'â€˜non-codingâ€™', 'areas', 'that', 'make', 'up', 'the', 'majority', 'of', 'our', 'complete set of genetic instructions', '.', 'these', 'mutations', 'do', 'not', 'modify', 'proteins', 'directly', ',', 'which', 'makes', 'it', 'challenging', 'to', 'understand', 'how', 'they', 'may', 'be', 'related', 'to', 'heart', 'conditions', '.', 'one', 'possibility', 'is', 'that', 'the', 'genetic', 'changes', 'affect', 'regions', 'called', 'enhancers', ',', 'which', 'control', 'where', ',', 'when', 'and', 'how', 'much', 'a', 'gene', 'is', 'turned', 'on', 'by', 'physically', 'interacting', 'with', 'it', '.', 'mutations', 'in', 'enhancers', 'could', 'lead', 'to', 'a', 'gene', 'producing', 'too', 'much', 'or', 'too', 'little', 'of', 'a', 'protein', ',', 'which', 'might', 'create', 'problems', 'in', 'the', 'cell', '.', 'yet', ',', 'it', 'is', 'difficult', 'to', 'match', 'an', 'enhancer', 'with', 'the', 'gene', 'or', 'genes', 'it', 'controls', '.', 'one', 'reason', 'is', 'that', 'a', 'non-coding', 'region', 'can', 'influence', 'a', 'gene', 'placed', 'far', 'away', 'on', 'the', 'dna', 'strand', '.', 'indeed', ',', 'the', 'long', 'dna', 'molecule', 'precisely', 'folds', 'in', 'on', 'itself', 'to', 'fit', 'inside', 'its', 'compartment', 'in', 'the', 'cell', ',', 'which', 'can', 'bring', 'together', 'distant', 'sequences', '.', 'montefiori', 'et', 'al', '.', 'take', 'over', '500', 'non-coding', 'areas', ',', 'which', 'can', 'carry', 'mutations', 'associated', 'with', 'heart', 'diseases', ',', 'and', 'use', 'a', 'technique', 'called', 'hi-c', 'to', 'try', 'to', 'identify', 'which', 'genes', 'these', 'regions', 'may', 'control', '.', 'the', 'tool', 'can', 'model', 'the', '3d', 'organization', 'of', 'the', 'complete set of genetic instructions', ',', 'and', 'it', 'was', 'further', 'modified', 'to', 'capture', 'only', 'the', 'regions', 'of', 'the', 'complete set of genetic instructions', 'that', 'contain', 'genes', ',', 'and', 'the', 'dna', 'sequences', 'that', 'interact', 'with', 'them', ',', 'in', 'human', 'heart', 'cells', '.', 'this', 'helped', 'to', 'create', 'a', '3d', 'map', 'of', '347', 'genes', 'which', 'come', 'in', 'contact', 'with', 'the', 'non-coding', 'areas', 'that', 'carry', 'mutations', 'associated', 'with', 'heart', 'diseases', '.', 'in', 'fact', ',', 'deleting', 'those', 'genes', 'often', 'causes', 'heart', 'disorders', 'in', 'mice', '.', 'in', 'addition', ',', 'montefiori', 'et', 'al', '.', 'reveal', 'that', '90%', 'of', 'the', 'non-coding', 'regions', 'examined', 'were', 'influencing', 'genes', 'that', 'were', 'far', 'away', '.', 'this', 'shows', 'that', ',', 'despite', 'a', 'common', 'assumption', ',', 'enhancers', 'often', 'do', 'not', 'regulate', 'the', 'coding', 'sequences', 'they', 'are', 'nearest', 'to', 'on', 'the', 'dna', 'strand', '.', 'pinpointing', 'the', 'genes', 'regulated', 'by', 'the', 'non-coding', 'regions', 'involved', 'in', 'cardiovascular', 'diseases', 'could', 'lead', 'to', 'new', 'ways', 'of', 'treating', 'or', 'preventing', 'these', 'conditions', '.', 'the', '3d', 'map', 'created', 'by', 'montefiori', 'et', 'al', '.', 'may', 'also', 'help', 'to', 'visualize', 'how', 'the', 'genetic', 'information', 'is', 'organized', 'in', 'heart', 'cells', '.', 'this', 'will', 'contribute', 'to', 'the', 'current', 'effort', 'to', 'understand', 'the', 'role', 'of', 'the', '3d', 'structure', 'of', 'the', 'complete set of genetic instructions', ',', 'especially', 'in', 'different', 'cell', 'types', '.']]\n"
     ]
    }
   ],
   "source": [
    "# MAIN LOOP\n",
    "data = df_elife_train # THis is the dataframe\n",
    "og_summ_list = df_elife_train.summary.tolist()\n",
    "og_summ_list = [og_summ_list[28]] # For now just have one document to test with\n",
    "layterm_summaries = [] # Collect layterm summaries \n",
    "\n",
    "for summ in og_summ_list: # For every summary in the data (currently elife_train, can be changed above)\n",
    "    raw, lemma = make_lemma_doc(summ) # Make raw and lemma versions of the summary\n",
    "    find_and_replace(raw, lemma)\n",
    "    layterm_summaries.append(raw) # Add the new summary to the list\n",
    "\n",
    "print(layterm_summaries)\n",
    "\n",
    "# Save the summaries as a new column in thedataframe\n",
    "#data['tfidf_summary'] = layterm_summaries "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5133bb3e",
   "metadata": {},
   "source": [
    "Below is a sample method for skipping words if they are already defined in the summary, using lists of key phrases. - Avery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e409c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE FUNCTION FOR SKIPPING PHRASES\n",
    "after_skip_phrases = [[\"also\", \"known\", \"as\"]] # List of phrases after the word that makes it skipable \n",
    "prev_skip_phrases = [[\"known\", \"as\"]] # List of phrases BEFORE the word that makes it skipable\n",
    "\n",
    "max_after_skip = 3 # Longest length of an after_skip phrase\n",
    "max_prev_skip = 3 # Longest length of a before_skip phrase\n",
    "\n",
    "def skip(raw, index):\n",
    "    skip = False # Set skip to false at first\n",
    "    # Check after words\n",
    "\n",
    "    after_phrase = [] # To save the following phrase\n",
    "    for i in range(1, max_after_skip + 1): # Look at next words\n",
    "        new_index = index + i # Index of the neighbor\n",
    "        if new_index < len(raw): # Make sure inex in range\n",
    "            after_phrase.append(raw[new_index])\n",
    "            if after_phrase in after_skip_phrases: # If it's a skip phrase\n",
    "                skip = True # Change skip to true\n",
    "                break # Leave the loop\n",
    "        else: # If the index is out of range then so will the next one\n",
    "            break \n",
    "    \n",
    "    if skip == True: # If the skip is true already then there's no point in continuing\n",
    "        return skip\n",
    "    \n",
    "    prev_phrase = [] # TO save the previous phrase\n",
    "    for i in range(1, max_prev_skip + 1): # Look at previous words\n",
    "        new_index = index - i \n",
    "        if new_index > -1:\n",
    "            prev_phrase = [raw[index-i]] + prev_phrase # Update the prev phrase\n",
    "            if prev_phrase in prev_skip_phrases:\n",
    "                skip = True\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return skip "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b7841a",
   "metadata": {},
   "source": [
    "The next cell is the same find/replace method but with a test statement for skip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3c3853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW FIND/REPLACE WITH SKIP\n",
    "def find_and_replace(raw, lemma):\n",
    "    \"\"\"function for matching the location in the raw doc with contents of the lemma doc at the parallel location\"\"\"\n",
    "    for word_id in range(0, len(lemma)): # For every word in the document\n",
    "        if skip(raw, word_id) == False: # If not a skip word\n",
    "            curr_lemma_pos = lemma[word_id] # Get the current lemma,POS pair\n",
    "            curr_lemma = curr_lemma_pos[0] # Get the current word's lemma\n",
    "            if curr_lemma in term_dict: # If the lemma is in the dictionary\n",
    "                replace_options = term_dict[curr_lemma] # Get the list of replacement options\n",
    "                for layterm_tag in replace_options: # For every layterm, POS pair in the options\n",
    "                    if curr_lemma_pos[1] == layterm_tag[1]: # If the current POS matches the layterm POS\n",
    "                        raw[word_id] = layterm_tag[0] # Replace the word in the raw doc with the new replacement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad51bb3",
   "metadata": {},
   "source": [
    "The next cell just tests the skip method by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04a757b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "test_raw = [\"this\", \"test\", \"also\", \"known\", \"as\"]\n",
    "result = skip(test_raw, 1)\n",
    "print(result)\n",
    "\n",
    "test_raw = [\"this\", \"test\", \"is\", \"false\"]\n",
    "result = skip(test_raw, 1)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e06acf",
   "metadata": {},
   "source": [
    "Below is the same main training loop but testing summaries with skip_phrases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "765435fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'genomes', 'also', 'known', 'as', 'genetic', 'instructions', 'are', 'important', 'for', 'survival', '.', 'complete sets of genetic instructions', 'help', 'our', 'bodies', 'in', 'many', 'ways', '.'], ['next,', 'we', 'discuss', 'complete sets of genetic instructions', '.', 'the', 'genetic', 'instructions', 'known', 'as', 'genomes', 'help', 'our', 'bodies', '.']]\n"
     ]
    }
   ],
   "source": [
    "# MAIN LOOP\n",
    "og_summ_list = [\"The genomes also known as genetic instructions are important for survival . Genomes help our bodies in many ways .\", \"Next, we discuss genomes . The genetic instructions known as genomes help our bodies .\"] # Test the new skip method\n",
    "layterm_summaries = [] # Collect layterm summaries \n",
    "\n",
    "for summ in og_summ_list: # For every summary in the data (currently elife_train, can be changed above)\n",
    "    raw, lemma = make_lemma_doc(summ) # Make raw and lemma versions of the summary\n",
    "    find_and_replace(raw, lemma)\n",
    "    layterm_summaries.append(raw) # Add the new summary to the list\n",
    "\n",
    "print(layterm_summaries)\n",
    "\n",
    "# Save the summaries as a new column in thedataframe\n",
    "#data['tfidf_summary'] = layterm_summaries "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
