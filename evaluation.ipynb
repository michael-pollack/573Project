{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d275f099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mermaid-python\n",
      "  Downloading mermaid_python-0.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: ipython in /home/jen/miniconda3/envs/573/lib/python3.11/site-packages (from mermaid-python) (9.1.0)\n",
      "Requirement already satisfied: decorator in /home/jen/miniconda3/envs/573/lib/python3.11/site-packages (from ipython->mermaid-python) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /home/jen/miniconda3/envs/573/lib/python3.11/site-packages (from ipython->mermaid-python) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/jen/miniconda3/envs/573/lib/python3.11/site-packages (from ipython->mermaid-python) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/jen/miniconda3/envs/573/lib/python3.11/site-packages (from ipython->mermaid-python) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/jen/miniconda3/envs/573/lib/python3.11/site-packages (from ipython->mermaid-python) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/jen/miniconda3/envs/573/lib/python3.11/site-packages (from ipython->mermaid-python) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/jen/miniconda3/envs/573/lib/python3.11/site-packages (from ipython->mermaid-python) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /home/jen/miniconda3/envs/573/lib/python3.11/site-packages (from ipython->mermaid-python) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /home/jen/miniconda3/envs/573/lib/python3.11/site-packages (from ipython->mermaid-python) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /home/jen/miniconda3/envs/573/lib/python3.11/site-packages (from ipython->mermaid-python) (4.13.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/jen/miniconda3/envs/573/lib/python3.11/site-packages (from jedi>=0.16->ipython->mermaid-python) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/jen/miniconda3/envs/573/lib/python3.11/site-packages (from pexpect>4.3->ipython->mermaid-python) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/jen/miniconda3/envs/573/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython->mermaid-python) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/jen/miniconda3/envs/573/lib/python3.11/site-packages (from stack_data->ipython->mermaid-python) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/jen/miniconda3/envs/573/lib/python3.11/site-packages (from stack_data->ipython->mermaid-python) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /home/jen/miniconda3/envs/573/lib/python3.11/site-packages (from stack_data->ipython->mermaid-python) (0.2.3)\n",
      "Downloading mermaid_python-0.1-py3-none-any.whl (3.2 kB)\n",
      "Installing collected packages: mermaid-python\n",
      "Successfully installed mermaid-python-0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mermaid-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6ca631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"mermaid\">\n",
       "sequenceDiagram\n",
       "  participant main as Main\n",
       "  participant evaluate as Evaluate Function\n",
       "  participant read_file_lines as Read File Lines\n",
       "  participant calc_rouge as Calculate ROUGE\n",
       "  participant calc_bertscore as Calculate BERTScore\n",
       "  participant calc_readability as Calculate Readability\n",
       "  participant calc_lens as Calculate LENS\n",
       "  participant calc_alignscore as Calculate AlignScore\n",
       "  participant cal_summac as Calculate SummaC\n",
       "  participant write_scores as Write Scores\n",
       "\n",
       "  Main->>evaluate: Calls evaluate(pred_path, gold_path)\n",
       "  activate evaluate\n",
       "  evaluate->>read_file_lines: Reads predictions and references\n",
       "  activate read_file_lines\n",
       "  read_file_lines-->>evaluate: Returns predictions and references\n",
       "  deactivate read_file_lines\n",
       "  evaluate->>calc_rouge: Calculates ROUGE scores\n",
       "  activate calc_rouge\n",
       "  calc_rouge-->>evaluate: Returns ROUGE scores\n",
       "  deactivate calc_rouge\n",
       "  evaluate->>calc_bertscore: Calculates BERTScore\n",
       "  activate calc_bertscore\n",
       "  calc_bertscore-->>evaluate: Returns BERTScore\n",
       "  deactivate calc_bertscore\n",
       "  evaluate->>calc_readability: Calculates readability scores\n",
       "  activate calc_readability\n",
       "  calc_readability-->>evaluate: Returns readability scores\n",
       "  deactivate calc_readability\n",
       "  evaluate->>calc_lens: Calculates LENS score\n",
       "  activate calc_lens\n",
       "  calc_lens-->>evaluate: Returns LENS score\n",
       "  deactivate calc_lens\n",
       "  evaluate->>calc_alignscore: Calculates AlignScore\n",
       "  activate calc_alignscore\n",
       "  calc_alignscore-->>evaluate: Returns AlignScore\n",
       "  deactivate calc_alignscore\n",
       "  evaluate->>cal_summac: Calculates SummaC\n",
       "  activate cal_summac\n",
       "  cal_summac-->>evaluate: Returns SummaC\n",
       "  deactivate cal_summac\n",
       "  evaluate->>write_scores: Writes scores to file\n",
       "  activate write_scores\n",
       "  write_scores-->>evaluate: Returns\n",
       "  deactivate write_scores\n",
       "  evaluate-->>Main: Returns score_dict\n",
       "  deactivate evaluate\n",
       "</div>\n",
       "\n",
       "<script type=\"module\">\n",
       "import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';\n",
       "mermaid.initialize({startOnLoad:true});\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mermaid import Mermaid\n",
    "\n",
    "Mermaid('''\n",
    "sequenceDiagram\n",
    "  participant main as Main\n",
    "  participant evaluate as Evaluate Function\n",
    "  participant read_file_lines as Read File Lines\n",
    "  participant calc_rouge as Calculate ROUGE\n",
    "  participant calc_bertscore as Calculate BERTScore\n",
    "  participant calc_readability as Calculate Readability\n",
    "  participant calc_lens as Calculate LENS\n",
    "  participant calc_alignscore as Calculate AlignScore\n",
    "  participant cal_summac as Calculate SummaC\n",
    "  participant write_scores as Write Scores\n",
    "\n",
    "  Main->>evaluate: Calls evaluate(pred_path, gold_path)\n",
    "  activate evaluate\n",
    "  evaluate->>read_file_lines: Reads predictions and references\n",
    "  activate read_file_lines\n",
    "  read_file_lines-->>evaluate: Returns predictions and references\n",
    "  deactivate read_file_lines\n",
    "  evaluate->>calc_rouge: Calculates ROUGE scores\n",
    "  activate calc_rouge\n",
    "  calc_rouge-->>evaluate: Returns ROUGE scores\n",
    "  deactivate calc_rouge\n",
    "  evaluate->>calc_bertscore: Calculates BERTScore\n",
    "  activate calc_bertscore\n",
    "  calc_bertscore-->>evaluate: Returns BERTScore\n",
    "  deactivate calc_bertscore\n",
    "  evaluate->>calc_readability: Calculates readability scores\n",
    "  activate calc_readability\n",
    "  calc_readability-->>evaluate: Returns readability scores\n",
    "  deactivate calc_readability\n",
    "  evaluate->>calc_lens: Calculates LENS score\n",
    "  activate calc_lens\n",
    "  calc_lens-->>evaluate: Returns LENS score\n",
    "  deactivate calc_lens\n",
    "  evaluate->>calc_alignscore: Calculates AlignScore\n",
    "  activate calc_alignscore\n",
    "  calc_alignscore-->>evaluate: Returns AlignScore\n",
    "  deactivate calc_alignscore\n",
    "  evaluate->>cal_summac: Calculates SummaC\n",
    "  activate cal_summac\n",
    "  cal_summac-->>evaluate: Returns SummaC\n",
    "  deactivate cal_summac\n",
    "  evaluate->>write_scores: Writes scores to file\n",
    "  activate write_scores\n",
    "  write_scores-->>evaluate: Returns\n",
    "  deactivate write_scores\n",
    "  evaluate-->>Main: Returns score_dict\n",
    "  deactivate evaluate\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30482e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "573",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
